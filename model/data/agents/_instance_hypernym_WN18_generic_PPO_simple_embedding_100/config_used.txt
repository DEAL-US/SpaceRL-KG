multithreaded_dist_reward: False
guided_reward: True
guided_to_compute: ['terminal', 'embedding']
use_LSTM: True
use_episodes: False
episodes: 0
alpha: 0.9
gamma: 0.99
learning_rate: 0.001
activation: leaky_relu
regularizers: ['kernel']
algorithm: PPO
reward_type: simple
action_picking_policy: probability
reward_computation: one_hot_max
path_length: 3
laps: 100
dataset: WN18RR
single_relation_pair: [True, '_instance_hypernym']
name: _instance_hypernym_WN18_generic_PPO_simple_embedding_100
embeddings: ['TransE_l2']
embedding: TransE_l2
